{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJxk8Fe43254"
   },
   "source": [
    "**Creating a csv file which has the path of images and its name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cache cleared.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "cache_path = os.path.expanduser(r\"C:\\Users\\SAHIL\\AppData\\Local\\Temp\\tfhub_modules\")\n",
    "shutil.rmtree(cache_path)\n",
    "print(\"✅ Cache cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37bAZ9Qp6UQM",
    "outputId": "a438f5db-01e0-4897-dbb2-85a45be1b637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load MoveNet Thunder Model\n",
    "model_url = \"https://tfhub.dev/google/movenet/singlepose/thunder/4\"\n",
    "movenet = hub.load(model_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset Created: yoga_keypoints.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to extract keypoints from an image\n",
    "def extract_keypoints(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.expand_dims(img, axis=0).astype(np.int32)\n",
    "\n",
    "    outputs = movenet.signatures[\"serving_default\"](input=img)\n",
    "    keypoints = outputs['output_0'].numpy().reshape(-1, 3)[:, :2]  # Extract (x, y)\n",
    "\n",
    "    return keypoints.flatten()\n",
    "\n",
    "# Directory where images are stored (organized by pose names)\n",
    "images_dir = \"images\"\n",
    "\n",
    "data, labels = [], []\n",
    "for pose in os.listdir(images_dir):\n",
    "    pose_path = os.path.join(images_dir, pose)\n",
    "    if os.path.isdir(pose_path):\n",
    "        for img_file in os.listdir(pose_path):\n",
    "            img_path = os.path.join(pose_path, img_file)\n",
    "            keypoints = extract_keypoints(img_path)\n",
    "            data.append(keypoints)\n",
    "            labels.append(pose)  # Use folder name as label\n",
    "\n",
    "# Save dataset to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df[\"label\"] = labels\n",
    "df.to_csv(\"yoga_keypoints.csv\", index=False)\n",
    "print(\"✅ Dataset Created: yoga_keypoints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "60s7a80QIA_P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained with 100.00% accuracy.\n",
      "✅ Model saved as yoga_pose_model.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"yoga_keypoints.csv\")\n",
    "X, y = df.iloc[:, :-1].values, df[\"label\"].values\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest model\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save trained model\n",
    "joblib.dump(model, \"yoga_pose_model.pkl\")\n",
    "print(f\"✅ Model trained with {model.score(X_test, y_test) * 100:.2f}% accuracy.\")\n",
    "print(\"✅ Model saved as yoga_pose_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"failure\",\n",
      "  \"pose\": \"baddha konasana\",\n",
      "  \"confidence\": 0.535,\n",
      "  \"rating\": null,\n",
      "  \"feedback\": null,\n",
      "  \"corrections\": [],\n",
      "  \"errors\": [\n",
      "    \"Pose detected with low confidence.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load MoveNet Thunder Model\n",
    "model_url = \"https://tfhub.dev/google/movenet/singlepose/thunder/4\"\n",
    "movenet = hub.load(model_url)\n",
    "\n",
    "# Load trained model & dataset\n",
    "classifier = joblib.load(\"yoga_pose_model.pkl\")\n",
    "df = pd.read_csv(\"yoga_keypoints.csv\")\n",
    "ideal_keypoints = df.groupby(\"label\").mean().to_dict(orient=\"index\")\n",
    "\n",
    "# Keypoint labels for reference\n",
    "KEYPOINT_LABELS = [\n",
    "    \"Nose\", \"Left Eye\", \"Right Eye\", \"Left Ear\", \"Right Ear\", \n",
    "    \"Left Shoulder\", \"Right Shoulder\", \"Left Elbow\", \"Right Elbow\", \n",
    "    \"Left Wrist\", \"Right Wrist\", \"Left Hip\", \"Right Hip\",\n",
    "    \"Left Knee\", \"Right Knee\", \"Left Ankle\", \"Right Ankle\"\n",
    "]\n",
    "\n",
    "# Function to extract keypoints from a frame\n",
    "def extract_keypoints_from_frame(frame):\n",
    "    img = cv2.resize(frame, (256, 256))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.expand_dims(img, axis=0).astype(np.int32)\n",
    "\n",
    "    outputs = movenet.signatures[\"serving_default\"](input=img)\n",
    "    keypoints = outputs[\"output_0\"].numpy().reshape(-1, 3)\n",
    "\n",
    "    # Keep only (x, y) coordinates, ignore confidence scores\n",
    "    keypoints = keypoints[:, :2]\n",
    "\n",
    "    return keypoints.flatten(), keypoints  # Flattened & full keypoints\n",
    "\n",
    "# Enhanced function to check if enough keypoints are detected\n",
    "def is_valid_pose(keypoints_array):\n",
    "    # Check that we have at least 15 keypoints detected (out of 17)\n",
    "    visible_joints = np.count_nonzero(keypoints_array[:, 0])\n",
    "    if visible_joints < 15:\n",
    "        return False\n",
    "    \n",
    "    # Define critical joints that must be visible\n",
    "    critical_joints = {\n",
    "        'shoulders': [5, 6],  # Left and right shoulder\n",
    "        'hips': [11, 12],     # Left and right hip\n",
    "        'knees': [13, 14],    # Left and right knee\n",
    "        'ankles': [15, 16]    # Left and right ankle\n",
    "    }\n",
    "    \n",
    "    # Check all critical joints are detected\n",
    "    for joint_type, indices in critical_joints.items():\n",
    "        if not all(keypoints_array[i, 0] > 0 for i in indices):\n",
    "            return False\n",
    "    \n",
    "    # Additional check: ensure body proportions are reasonable\n",
    "    # Calculate distance between shoulders\n",
    "    shoulder_width = distance.euclidean(keypoints_array[5][:2], keypoints_array[6][:2])\n",
    "    # Calculate distance from shoulder to hip\n",
    "    torso_height = distance.euclidean(keypoints_array[5][:2], keypoints_array[11][:2])\n",
    "    \n",
    "    # If proportions are unrealistic (too wide or too narrow)\n",
    "    if shoulder_width < 0.1 or shoulder_width > 0.5 or torso_height < 0.1:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Function to calculate corrections & rating\n",
    "def calculate_corrections(detected_keypoints, ideal_pose_keypoints_dict):\n",
    "    corrections = []\n",
    "    total_diff = 0\n",
    "    num_compared = 0\n",
    "\n",
    "    # Convert ideal keypoints to numpy array\n",
    "    ideal_pose_keypoints = np.zeros(len(KEYPOINT_LABELS)*2)\n",
    "    for i in range(len(KEYPOINT_LABELS)):\n",
    "        ideal_pose_keypoints[i*2] = ideal_pose_keypoints_dict[f\"{i*2}\"]\n",
    "        ideal_pose_keypoints[i*2+1] = ideal_pose_keypoints_dict[f\"{i*2+1}\"]\n",
    "\n",
    "    for i, label in enumerate(KEYPOINT_LABELS):\n",
    "        detected = detected_keypoints[i*2:i*2+2]\n",
    "        ideal = ideal_pose_keypoints[i*2:i*2+2]\n",
    "\n",
    "        if np.all(detected > 0) and np.all(ideal > 0):  # Only compare if both are detected\n",
    "            diff = distance.euclidean(detected, ideal)\n",
    "            total_diff += diff\n",
    "            num_compared += 1\n",
    "            if diff > 0.15:  # Adjusted threshold for normalized coordinates\n",
    "                direction = \"\"\n",
    "                if detected[0] - ideal[0] > 0.05:\n",
    "                    direction += \"move left \"\n",
    "                elif detected[0] - ideal[0] < -0.05:\n",
    "                    direction += \"move right \"\n",
    "                \n",
    "                if detected[1] - ideal[1] > 0.05:\n",
    "                    direction += \"move up \"\n",
    "                elif detected[1] - ideal[1] < -0.05:\n",
    "                    direction += \"move down \"\n",
    "                \n",
    "                if direction:\n",
    "                    corrections.append(f\"Adjust {label}: {direction.strip()}\")\n",
    "\n",
    "    if num_compared > 0:\n",
    "        avg_diff = total_diff / num_compared\n",
    "        rating = max(10 - int(avg_diff / 0.05), 1)  # Adjusted rating calculation\n",
    "    else:\n",
    "        rating = 1\n",
    "\n",
    "    return corrections, rating\n",
    "\n",
    "# Main execution\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(json.dumps({\n",
    "            \"status\": \"failure\",\n",
    "            \"pose\": None,\n",
    "            \"confidence\": None,\n",
    "            \"rating\": None,\n",
    "            \"feedback\": None,\n",
    "            \"corrections\": [],\n",
    "            \"errors\": [\"Could not open webcam.\"]\n",
    "        }, indent=2))\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "    frames = []\n",
    "    valid_frames = 0\n",
    "\n",
    "    while time.time() - start_time < 15:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        keypoints_flat, keypoints_array = extract_keypoints_from_frame(frame)\n",
    "        if is_valid_pose(keypoints_array):\n",
    "            frames.append((keypoints_flat, keypoints_array))\n",
    "            valid_frames += 1\n",
    "\n",
    "        cv2.putText(frame, \"Hold your yoga pose for 15 seconds\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Time remaining: {int(15 - (time.time() - start_time))}s\", \n",
    "                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Yoga Pose Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if valid_frames < 5:\n",
    "        result = {\n",
    "            \"status\": \"failure\",\n",
    "            \"pose\": None,\n",
    "            \"confidence\": None,\n",
    "            \"rating\": None,\n",
    "            \"feedback\": None,\n",
    "            \"corrections\": [],\n",
    "            \"errors\": [\n",
    "                \"Could not detect a valid yoga pose.\",\n",
    "                \"Make sure your full body is visible.\",\n",
    "                \"Improve lighting or camera position.\",\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        best_frame = max(frames, key=lambda x: np.count_nonzero(x[1][:, 0]))\n",
    "        keypoints_flat, keypoints_array = best_frame\n",
    "        keypoints_flat = keypoints_flat.reshape(1, -1)\n",
    "\n",
    "        pose_probabilities = classifier.predict_proba(keypoints_flat)\n",
    "        predicted_pose = classifier.predict(keypoints_flat)[0]\n",
    "        max_confidence = float(np.max(pose_probabilities))\n",
    "\n",
    "        if max_confidence < 0.85 or predicted_pose not in ideal_keypoints:\n",
    "            result = {\n",
    "                \"status\": \"failure\",\n",
    "                \"pose\": predicted_pose,\n",
    "                \"confidence\": max_confidence,\n",
    "                \"rating\": None,\n",
    "                \"feedback\": None,\n",
    "                \"corrections\": [],\n",
    "                \"errors\": [\"Pose detected with low confidence.\"]\n",
    "            }\n",
    "        else:\n",
    "            corrections, rating = calculate_corrections(keypoints_flat.flatten(), ideal_keypoints[predicted_pose])\n",
    "\n",
    "            if rating >= 8:\n",
    "                feedback = \"Excellent form! Keep it up! 💪\"\n",
    "            elif rating >= 5:\n",
    "                feedback = \"Good attempt! Some minor adjustments needed.\"\n",
    "            else:\n",
    "                feedback = \"Needs work. Focus on the corrections below.\"\n",
    "\n",
    "            result = {\n",
    "                \"status\": \"success\",\n",
    "                \"pose\": predicted_pose,\n",
    "                \"confidence\": max_confidence,\n",
    "                \"rating\": rating,\n",
    "                \"feedback\": feedback,\n",
    "                \"corrections\": corrections if corrections else [\"No major corrections needed! Perfect pose! 🎉\"],\n",
    "                \"errors\": []\n",
    "            }\n",
    "\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
