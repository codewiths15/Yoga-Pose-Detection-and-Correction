{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJxk8Fe43254"
   },
   "source": [
    "**Creating a csv file which has the path of images and its name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37bAZ9Qp6UQM",
    "outputId": "a438f5db-01e0-4897-dbb2-85a45be1b637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAHIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset Created: yoga_keypoints.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "\n",
    "# Load MoveNet Thunder Model\n",
    "model_url = \"https://tfhub.dev/google/movenet/singlepose/thunder/4\"\n",
    "movenet = hub.load(model_url)\n",
    "\n",
    "# Function to extract keypoints from an image\n",
    "def extract_keypoints(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.expand_dims(img, axis=0).astype(np.int32)\n",
    "\n",
    "    outputs = movenet.signatures[\"serving_default\"](input=img)\n",
    "    keypoints = outputs['output_0'].numpy().reshape(-1, 3)[:, :2]  # Extract (x, y)\n",
    "\n",
    "    return keypoints.flatten()\n",
    "\n",
    "# Directory where images are stored (organized by pose names)\n",
    "images_dir = \"images\"\n",
    "\n",
    "data, labels = [], []\n",
    "for pose in os.listdir(images_dir):\n",
    "    pose_path = os.path.join(images_dir, pose)\n",
    "    if os.path.isdir(pose_path):\n",
    "        for img_file in os.listdir(pose_path):\n",
    "            img_path = os.path.join(pose_path, img_file)\n",
    "            keypoints = extract_keypoints(img_path)\n",
    "            data.append(keypoints)\n",
    "            labels.append(pose)  # Use folder name as label\n",
    "\n",
    "# Save dataset to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df[\"label\"] = labels\n",
    "df.to_csv(\"yoga_keypoints.csv\", index=False)\n",
    "print(\"✅ Dataset Created: yoga_keypoints.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "60s7a80QIA_P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained with 100.00% accuracy.\n",
      "✅ Model saved as yoga_pose_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"yoga_keypoints.csv\")\n",
    "X, y = df.iloc[:, :-1].values, df[\"label\"].values\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest model\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save trained model\n",
    "joblib.dump(model, \"yoga_pose_model.pkl\")\n",
    "print(f\"✅ Model trained with {model.score(X_test, y_test) * 100:.2f}% accuracy.\")\n",
    "print(\"✅ Model saved as yoga_pose_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: No ideal keypoints found for baddha konasana\n",
      "✅ Predicted Pose: baddha konasana\n",
      "✅ Rating: 0/10\n",
      "✅ Corrections Needed:\n",
      "   - Error: Ideal keypoints not found\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Load MoveNet Thunder Model\n",
    "model_url = \"https://tfhub.dev/google/movenet/singlepose/thunder/4\"\n",
    "movenet = hub.load(model_url)\n",
    "\n",
    "# Load trained model\n",
    "classifier = joblib.load(\"yoga_pose_model.pkl\")\n",
    "\n",
    "# Load dataset to get ideal keypoints for each pose\n",
    "df = pd.read_csv(\"yoga_keypoints.csv\")\n",
    "ideal_keypoints = df.groupby(\"label\").mean().to_dict(orient=\"index\")  # Average keypoints for each pose\n",
    "\n",
    "# Function to extract keypoints from a frame\n",
    "def extract_keypoints_from_frame(frame):\n",
    "    img = cv2.resize(frame, (256, 256))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.expand_dims(img, axis=0).astype(np.int32)\n",
    "\n",
    "    outputs = movenet.signatures[\"serving_default\"](input=img)\n",
    "    keypoints = outputs[\"output_0\"].numpy().reshape(-1, 3)[:, :2]\n",
    "\n",
    "    return keypoints.flatten()\n",
    "\n",
    "# Function to calculate corrections & rating\n",
    "def calculate_corrections(detected_keypoints, ideal_keypoints):\n",
    "    corrections = []\n",
    "    keypoint_labels = [\n",
    "        \"Nose\", \"Left Eye\", \"Right Eye\", \"Left Ear\", \"Right Ear\", \"Left Shoulder\", \"Right Shoulder\",\n",
    "        \"Left Elbow\", \"Right Elbow\", \"Left Wrist\", \"Right Wrist\", \"Left Hip\", \"Right Hip\",\n",
    "        \"Left Knee\", \"Right Knee\", \"Left Ankle\", \"Right Ankle\"\n",
    "    ]\n",
    "\n",
    "    # Check if predicted pose exists in ideal_keypoints\n",
    "    if predicted_pose not in ideal_keypoints:\n",
    "        print(f\"⚠️ Warning: No ideal keypoints found for {predicted_pose}\")\n",
    "        return [\"Error: Ideal keypoints not found\"], 0  # Error message and rating 0\n",
    "\n",
    "    ideal_pose_keypoints = np.array(ideal_keypoints[predicted_pose])  # Convert to NumPy array\n",
    "    total_diff = 0\n",
    "\n",
    "    for i, label in enumerate(keypoint_labels):\n",
    "        detected = detected_keypoints[i * 2:i * 2 + 2]  # (x, y)\n",
    "        ideal = ideal_pose_keypoints[i * 2:i * 2 + 2]  # (x, y)\n",
    "\n",
    "        if len(detected) == 2 and len(ideal) == 2:\n",
    "            diff = distance.euclidean(detected, ideal)\n",
    "            total_diff += diff\n",
    "            if diff > 20:  # Threshold for correction\n",
    "                corrections.append(f\"Adjust {label} closer to ideal position\")\n",
    "\n",
    "    avg_diff = total_diff / len(keypoint_labels)\n",
    "    rating = max(10 - int(avg_diff / 5), 1)  # Convert avg_diff to rating (1-10 scale)\n",
    "\n",
    "    return corrections, rating\n",
    "\n",
    "# Capture image from webcam, process it, and display output in VS Code\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    keypoints = extract_keypoints_from_frame(frame).reshape(1, -1)\n",
    "    predicted_pose = classifier.predict(keypoints)[0]\n",
    "\n",
    "    corrections, rating = calculate_corrections(keypoints.flatten(), ideal_keypoints[predicted_pose])\n",
    "\n",
    "    print(f\"✅ Predicted Pose: {predicted_pose}\")\n",
    "    print(f\"✅ Rating: {rating}/10\")\n",
    "    print(\"✅ Corrections Needed:\")\n",
    "    for correction in corrections:\n",
    "        print(f\"   - {correction}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Could not capture an image from the webcam.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
